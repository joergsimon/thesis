{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Split\n",
    "\n",
    "In machine learning a common praxis is to split the data into random subsets for training, testing and validation. However, this praxis is often critisised as it is only for certain subsets of data (for those data where each instance really is i.i.d.) the best choice. If your data depends on each other, this splits are not valid. By using sliding windows I remove a part of the temporal dependencies. However, since the windows overlapp each other just using a random split gives a high probability the data was already seen. Therefor we need an other strategy for the train / validation / test set split. Especially cross validation is not easily done here.\n",
    "\n",
    "The strategy I choose therefor is the following: I save one random selected user for the test set. For the validation set I pick complete sections of windows over a label and some longer sections for the zero class. Since each user performs each of the 31 gestures at least 5 times (not completely true, because of data cleaning sometimes a label was removed) I select one of these repitions randomly from each user and remove all sequences into the validation set. I discard the overlapping zero class windows, as the zero class is dominant anyway, and that does not hurt the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "import pathlib\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import pandas as pd\n",
    "import gestureanalysis.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/jsimon/Documents/thesis/gesture-analysis/data/\"\n",
    "time_groups_path_corrected_pickl = base_path+\"transformed/time_added/all/time-and-groups-corrected-all.pkl\"\n",
    "stats_added_base_path = base_path+\"transformed/stats_added/all/\"\n",
    "stats_added_path_pickl = stats_added_base_path+\"raw_stats-added-all.pkl\"\n",
    "gyro_calibration_path = base_path+'../scripts/gestureanalysis/gyro_offset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jsimon/Documents/thesis/gesture-analysis/scripts'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check working directory and adopt if needed\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you need to reload, and know it exists:\n",
    "with open( time_groups_path_corrected_pickl, \"rb\" ) as users_pickle_file:\n",
    "    users = pickle.load(users_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data of CF58 as a test set\n",
    "path = f\"{stats_added_base_path}AB73-window-data.pkl\"\n",
    "with open( path, \"rb\" ) as windows_file:\n",
    "    testdata = pickle.load(windows_file)\n",
    "# honestly I do not use the code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just misuse user CF58 a bit here to explain the labels. We have a matrix of all gestures. For each window the number of how often that gesture is performed at that window is written in the label matrix. The gesture is way shorter than the window, but long enough to be captured by several windows. How many windows capture that gesture is different. However it is always a consecutive group of window indexes who see the gesture. We cound the number of groups for a gesture and select a random number. This gesture is taken away from the set into the validation set. Then the windows are deleted plus the windows till the next and previous gesture. If it was the first or the last gesture 20 windows are used as a default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2066    61\n",
       "2067    60\n",
       "2068    30\n",
       "2077    25\n",
       "2078    55\n",
       "2079    85\n",
       "2080    85\n",
       "2081    85\n",
       "2082    85\n",
       "2083    80\n",
       "Name: (1) One, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata['winlabels']['(1) One'][testdata['winlabels']['(1) One'] > 0][5:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_groups(occurences):\n",
    "    indexes = list(occurences.index)\n",
    "    groups = []\n",
    "    start = indexes[0]\n",
    "    for i in range(1,len(indexes)):\n",
    "        last = indexes[i-1]\n",
    "        current = indexes[i]\n",
    "        if current - last == 1:\n",
    "            continue\n",
    "        else:\n",
    "            groups.append((start, last))\n",
    "            start = current\n",
    "    groups.append((start, current))\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaps(groups):\n",
    "    for g1,g2 in zip(groups[1:], groups[:-1]):\n",
    "        print(f'gap: {g2[0] - g1[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append(list_of_dfs):\n",
    "    df = list_of_dfs[0]\n",
    "    for i in range(1, len(list_of_dfs)):\n",
    "        df = df.append(list_of_dfs[i], ignore_index=True)\n",
    "        df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nocat(list_of_dfs):\n",
    "    for df in list_of_dfs:\n",
    "        df.columns=df.columns.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_group(groups, selected):\n",
    "    if selected == 0:\n",
    "        start = groups[0][0] - 20\n",
    "    else:\n",
    "        start = groups[selected-1][1] # end of last group\n",
    "    \n",
    "    if selected == len(groups)-1:\n",
    "        end = groups[selected][1] + 20\n",
    "    else:\n",
    "        end = groups[selected+1][0] # start of next group\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_zero_class(df):\n",
    "    zero_idx = df[df.columns[0]] == 0\n",
    "    for c in df.columns[1:]:\n",
    "        zidx = df[c] == 0\n",
    "        zero_idx = zero_idx & zidx\n",
    "    return zero_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_groups_larger_than(groups, criterion):\n",
    "    deltas = map(lambda x: x[1] - x[0], groups)\n",
    "    filtered = filter(lambda x: x[0] > criterion, zip(deltas, groups))\n",
    "    filtered_groups = map(lambda x: x[1], filtered)\n",
    "    return list(filtered_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbfb896e2fc461fa83ac56efa06b00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=23), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user AB73 has 31\n",
      "added 31 gestures for AB73\n",
      "data len: 6093; label len: 6093\n",
      "after removel: data len: 5306; label len: 5306\n",
      "after zero removel: data len: 5276; label len: 5276\n",
      "skipping user AE30, no data\n",
      "user AF82 has 31\n",
      "added 31 gestures for AF82\n",
      "data len: 3521; label len: 3521\n",
      "after removel: data len: 2662; label len: 2662\n",
      "after zero removel: data len: 2557; label len: 2557\n",
      "user AL29 has 31\n",
      "added 31 gestures for AL29\n",
      "data len: 6135; label len: 6135\n",
      "after removel: data len: 5348; label len: 5348\n",
      "after zero removel: data len: 5348; label len: 5348\n",
      "user AW18 has 31\n",
      "added 31 gestures for AW18\n",
      "data len: 3431; label len: 3431\n",
      "after removel: data len: 2528; label len: 2528\n",
      "after zero removel: data len: 2528; label len: 2528\n",
      "user CB23 has 31\n",
      "added 31 gestures for CB23\n",
      "data len: 3504; label len: 3504\n",
      "after removel: data len: 2633; label len: 2633\n",
      "after zero removel: data len: 2546; label len: 2546\n",
      "user CB24 has 31\n",
      "added 31 gestures for CB24\n",
      "data len: 3529; label len: 3529\n",
      "after removel: data len: 2721; label len: 2721\n",
      "after zero removel: data len: 2689; label len: 2689\n",
      "user CF58 is kept away as a test\n",
      "user CF58 has 31\n",
      "added 31 gestures for CF58\n",
      "data len: 3969; label len: 3969\n",
      "after removel: data len: 3173; label len: 3173\n",
      "after zero removel: data len: 3051; label len: 3051\n",
      "user DG12 has 31\n",
      "added 31 gestures for DG12\n",
      "data len: 3478; label len: 3478\n",
      "after removel: data len: 2648; label len: 2648\n",
      "after zero removel: data len: 2618; label len: 2618\n",
      "user DH42 has 31\n",
      "added 31 gestures for DH42\n",
      "data len: 3674; label len: 3674\n",
      "after removel: data len: 2808; label len: 2808\n",
      "after zero removel: data len: 2779; label len: 2779\n",
      "user DL24 has 31\n",
      "added 31 gestures for DL24\n",
      "data len: 6035; label len: 6035\n",
      "after removel: data len: 5257; label len: 5257\n",
      "after zero removel: data len: 5225; label len: 5225\n",
      "user JL61 has 31\n",
      "added 31 gestures for JL61\n",
      "data len: 3745; label len: 3745\n",
      "after removel: data len: 2920; label len: 2920\n",
      "after zero removel: data len: 2821; label len: 2821\n",
      "user JQ28 has 31\n",
      "added 31 gestures for JQ28\n",
      "data len: 6379; label len: 6379\n",
      "after removel: data len: 5599; label len: 5599\n",
      "after zero removel: data len: 5504; label len: 5504\n",
      "user JS52 has 31\n",
      "added 31 gestures for JS52\n",
      "data len: 6240; label len: 6240\n",
      "after removel: data len: 5363; label len: 5363\n",
      "after zero removel: data len: 5295; label len: 5295\n",
      "user MF20 has 31\n",
      "added 31 gestures for MF20\n",
      "data len: 3427; label len: 3427\n",
      "after removel: data len: 2622; label len: 2622\n",
      "after zero removel: data len: 2622; label len: 2622\n",
      "user MS55 has 29\n",
      "added 29 gestures for MS55\n",
      "data len: 3621; label len: 3621\n",
      "after removel: data len: 2782; label len: 2782\n",
      "after zero removel: data len: 2748; label len: 2748\n",
      "user PC29 has 33\n",
      "added 33 gestures for PC29\n",
      "data len: 3997; label len: 3997\n",
      "after removel: data len: 2730; label len: 2730\n",
      "after zero removel: data len: 2675; label len: 2675\n",
      "user PM32 has 31\n",
      "added 31 gestures for PM32\n",
      "data len: 6015; label len: 6015\n",
      "after removel: data len: 5289; label len: 5289\n",
      "after zero removel: data len: 5258; label len: 5258\n",
      "user PS42 has 31\n",
      "added 31 gestures for PS42\n",
      "data len: 3519; label len: 3519\n",
      "after removel: data len: 2712; label len: 2712\n",
      "after zero removel: data len: 2712; label len: 2712\n",
      "user RR45 has 31\n",
      "added 31 gestures for RR45\n",
      "data len: 3515; label len: 3515\n",
      "after removel: data len: 2745; label len: 2745\n",
      "after zero removel: data len: 2745; label len: 2745\n",
      "user RW32 has 31\n",
      "added 31 gestures for RW32\n",
      "data len: 3520; label len: 3520\n",
      "after removel: data len: 2666; label len: 2666\n",
      "after zero removel: data len: 2636; label len: 2636\n",
      "user SF1 has 31\n",
      "added 31 gestures for SF1\n",
      "data len: 3433; label len: 3433\n",
      "after removel: data len: 2615; label len: 2615\n",
      "after zero removel: data len: 2585; label len: 2585\n",
      "user YW13 has 31\n",
      "added 31 gestures for YW13\n",
      "data len: 6229; label len: 6229\n",
      "after removel: data len: 5421; label len: 5421\n",
      "after zero removel: data len: 5392; label len: 5392\n",
      "\n",
      "704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsimon/anaconda3/envs/thesis/lib/python3.7/site-packages/pandas/core/frame.py:6701: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train validation split:\n",
    "\n",
    "# what is missing: a random zero class part\n",
    "lbl_dfs = []\n",
    "data_dfs = []\n",
    "\n",
    "lbl_train_dfs = []\n",
    "data_train_dfs = []\n",
    "for user, udata in tqdm.tqdm_notebook(users.items()):\n",
    "    if 'glove_merged' not in udata:\n",
    "        print(f\"skipping user {user}, no data\")\n",
    "        continue\n",
    "    if user == \"CF58\":\n",
    "        print(\"user CF58 is kept away as a test\")\n",
    "    path = f\"{stats_added_base_path}{user}-window-data.pkl\"\n",
    "    with open( path, \"rb\" ) as windows_file:\n",
    "        testdata = pickle.load(windows_file)\n",
    "    data = testdata['windata']\n",
    "    label = testdata['winlabels']\n",
    "    print(f'user {user} has {len(label.columns)}')\n",
    "    cnt = 0\n",
    "    smpls = 0\n",
    "    groups_to_remove = []\n",
    "    for gesture in label.columns:\n",
    "        occurences = label[gesture][label[gesture] > 0]\n",
    "        if len(occurences) == 0:\n",
    "            print(groups)\n",
    "            print('---------------------')\n",
    "            continue \n",
    "        groups = find_groups(occurences)\n",
    "        if len(groups) == 1:\n",
    "            print(groups)\n",
    "            print('---------------------')\n",
    "            continue \n",
    "        selected = np.random.randint(0, len(groups))\n",
    "        group = groups[selected]\n",
    "        lbl_windows = label[group[0]:group[1]].copy()\n",
    "        smpls += len(lbl_windows)\n",
    "        #print(f'add {len(lbl_windows)} of {gesture} for {user}')\n",
    "        data_windows = data[group[0]:group[1]].copy()\n",
    "        lbl_dfs.append(lbl_windows)\n",
    "        data_dfs.append(data_windows)\n",
    "        groups_to_remove.append(remove_group(groups, selected))\n",
    "        cnt += 1\n",
    "    print(f'added {cnt} gestures for {user}')\n",
    "    print(f'data len: {len(data)}; label len: {len(label)}')\n",
    "    for g in groups_to_remove:\n",
    "        s,e = g\n",
    "        idx = data[s:e].index\n",
    "        data = data.drop(idx, axis=0)\n",
    "        label = label.drop(idx, axis=0)\n",
    "    print(f'after removel: data len: {len(data)}; label len: {len(label)}')\n",
    "    \n",
    "    # transfer a sample for the zero class, delete the whole section\n",
    "    smpls = int(smpls / 31)\n",
    "    zero_remove = smpls + 20\n",
    "    zero_groups = find_groups(label[find_zero_class(label)])\n",
    "    candidates = filter_groups_larger_than(zero_groups, zero_remove)\n",
    "    selected = np.random.randint(0, len(candidates))\n",
    "    group = candidates[selected]\n",
    "    middle = ((group[1] - group[0])//2) + group[0]\n",
    "    sampleg = (middle-smpls//2, middle+smpls//2)\n",
    "    lbl_windows = label[sampleg[0]:sampleg[1]].copy()\n",
    "    data_windows = data[sampleg[0]:sampleg[1]].copy()\n",
    "    lbl_dfs.append(lbl_windows)\n",
    "    data_dfs.append(data_windows)\n",
    "    idx = data[group[0]:group[1]].index\n",
    "    data = data.drop(idx, axis=0)\n",
    "    label = label.drop(idx, axis=0)\n",
    "    \n",
    "    print(f'after zero removel: data len: {len(data)}; label len: {len(label)}')\n",
    "    \n",
    "    lbl_train_dfs.append(label)\n",
    "    data_train_dfs.append(data)\n",
    "    gc.collect()\n",
    "print(len(lbl_dfs))\n",
    "nocat(lbl_dfs)\n",
    "valid_label_df = append(lbl_dfs)\n",
    "valid_data_df = append(data_dfs)\n",
    "lbl_dfs = None\n",
    "data_dfs = None\n",
    "gc.collect()\n",
    "\n",
    "nocat(lbl_train_dfs)\n",
    "train_label_df = append(lbl_train_dfs)\n",
    "lbl_train_dfs = None\n",
    "gc.collect()\n",
    "train_data_df = append(data_train_dfs)\n",
    "data_train_dfs = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation data: 6186, train data: 77610\n",
      "validation data: 0.0738221, train data: 0.926178\n"
     ]
    }
   ],
   "source": [
    "print(f'validation data: {len(valid_data_df)}, train data: {len(train_data_df)}')\n",
    "n = len(train_data_df) + len(valid_data_df)\n",
    "print(f'validation data: {len(valid_data_df)/n:g}, train data: {len(train_data_df)/n:g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( stats_added_base_path+'validation.pkl', \"wb\" ) as users_pickle_file:\n",
    "    ds = { 'valid' : {'data' : valid_data_df, 'labels': valid_label_df} }\n",
    "    pickle.dump(ds, users_pickle_file)\n",
    "    \n",
    "with open( stats_added_base_path+'train.pkl', \"wb\" ) as users_pickle_file:\n",
    "    ds = { 'train' : {'data' : train_data_df, 'labels': train_label_df} }\n",
    "    pickle.dump(ds, users_pickle_file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7201"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
